{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsWx/JyVRFGNTbBFAPpMYn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinWahle/ASSD-TPF/blob/master/ASSD_Dialization%2BTranscriber.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dializator + Transcriber\n",
        "\n",
        "El objetivo de este notebook es: ...\n"
      ],
      "metadata": {
        "id": "5JIujQVI9JAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descarga e importación de librerías\n"
      ],
      "metadata": {
        "id": "JhIGozlZ9Sov"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku_YSSmd7I0T"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.system(\"pip install git+https://github.com/openai/whisper.git\")\n",
        "os.system(\"pip install git+https://github.com/resemble-ai/Resemblyzer.git\")\n",
        "os.system(\"pip install pathlib\")\n",
        "os.system(\"pip install librosa==0.9.2\")\n",
        "\n",
        "import whisper\n",
        "from resemblyzer import preprocess_wav, VoiceEncoder\n",
        "from pathlib import Path\n",
        "from scipy.io import wavfile\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dialización"
      ],
      "metadata": {
        "id": "tcVyUFtmDqzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga de Oradores"
      ],
      "metadata": {
        "id": "IGB-zUiM-gmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wav_fpath = \"/content/sample.wav\"\n",
        "wav = preprocess_wav(wav_fpath)\n",
        "sampling_rate=16000\n",
        "\n",
        "segments = [[0, 5.5], [6.5, 12], [17, 25]]                  #TODO: Ver cómo integrar a la GUI\n",
        "speaker_names = [\"Kyle Gass\", \"Sean Evans\", \"Jack Black\"]\n",
        "speaker_wavs = [wav[int(s[0] * sampling_rate):int(s[1] * sampling_rate)] for s in segments]"
      ],
      "metadata": {
        "id": "t-8cvtsz-yzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicación de la Red Neuronal"
      ],
      "metadata": {
        "id": "eOavDtSiC_xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Compare speaker embeds to the continuous embedding of the interview\n",
        "# Derive a continuous embedding of the interview. We put a rate of 16, meaning that an \n",
        "# embedding is generated every 0.0625 seconds. It is good to have a higher rate for speaker \n",
        "# diarization, but it is not so useful for when you only need a summary embedding of the \n",
        "# entire utterance. A rate of 2 would have been enough, but 16 is nice for the sake of the \n",
        "# demonstration. \n",
        "# We'll exceptionally force to run this on CPU, because it uses a lot of RAM and most GPUs \n",
        "# won't have enough. There's a speed drawback, but it remains reasonable.\n",
        "encoder = VoiceEncoder(\"cpu\")\n",
        "print(\"Running the continuous embedding on cpu, this might take a while...\")\n",
        "_, cont_embeds, wav_splits = encoder.embed_utterance(wav, return_partials=True, rate=16) \n",
        "\n",
        "# Get the continuous similarity for every speaker. It amounts to a dot product between the \n",
        "# embedding of the speaker and the continuous embedding of the interview\n",
        "speaker_embeds = [encoder.embed_utterance(speaker_wav) for speaker_wav in speaker_wavs]\n",
        "similarity_dict = {name: cont_embeds @ speaker_embed for name, speaker_embed in \n",
        "                   zip(speaker_names, speaker_embeds)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlF_fSKZDHYn",
        "outputId": "78433b39-f875-4d1d-e14e-7b34f4ab5e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
            "Running the continuous embedding on cpu, this might take a while...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prefiltrado de la dialización\n",
        "En esta etapa se busca: ... \n"
      ],
      "metadata": {
        "id": "SNj5y6QPDSo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "talk_names =[]\n",
        "MIN_PROB = 65/100\n",
        "\n",
        "\n",
        "for i in range(len(similarity_dict[speaker_names[0]])):     # Create an array with speaker predominance in each sample\n",
        "    prev = 0\n",
        "    for names in speaker_names:\n",
        "        prev= max(similarity_dict[names][i], prev)\n",
        "        if(prev==similarity_dict[names][i]): name = names\n",
        "    if prev<MIN_PROB: name = None\n",
        "    talk_names.append(name)\n",
        "\n",
        "# Si tuve 1 valor de 5 diferente, corregilo\n",
        "for i in range(len(talk_names)):                            # Soft change matrix \n",
        "    if 1<i<len(talk_names)-3 and talk_names[i-1]==talk_names[i-2]==talk_names[i+1]==talk_names[i+2]:\n",
        "        talk_names[i]=talk_names[i-1]\n",
        "\n",
        "# Crea arreglo con tiempos y nombres [[start,end,speaker]]\n",
        "name=talk_names[0]\n",
        "speakers_time = []\n",
        "prev_name=0\n",
        "io=0\n",
        "for i in range(len(talk_names)):\n",
        "    name=talk_names[i]\n",
        "    if name!=prev_name:\n",
        "        if prev_name!=None:\n",
        "            speakers_time.append([io,i,prev_name,\"\"])\n",
        "        io=i+1\n",
        "    prev_name=name\n",
        "\n",
        "# Si el delta_tiempo es menor a MIN_TIME, sacamelo\n",
        "# Si son tempos cercanos (menor a MIN_TIME), hace merge\n",
        "MIN_TIME = 4\n",
        "time_processed=[]\n",
        "for i in range(len(speakers_time)):\n",
        "    #Do merge\n",
        "    if len(time_processed) and speakers_time[i][2]==time_processed[-1:][0][2] and (speakers_time[i][0]-time_processed[-1:][0][1])<=MIN_TIME:\n",
        "        temp = time_processed[-1:][0][0]            # Guardo de la iteración anterior \n",
        "        time_processed.pop()                        # Saco el tiempo viejo\n",
        "        time_processed.append([temp, speakers_time[i][1], speakers_time[i][2], \"\"]) # Agrego el merge\n",
        "    #Delete time\n",
        "    elif (speakers_time[i][1]-speakers_time[i][0])>MIN_TIME:\n",
        "        if len(time_processed) and time_processed[-1:][0][1]-time_processed[-1:][0][0]<=MIN_TIME:\n",
        "            time_processed.pop()                    # Si el de la iteración anteior era menor, lo saco\n",
        "        time_processed.append(speakers_time[i])     # Agrego el tiempo si es mayor a mintime\n",
        "    #Append and check in next iteration\n",
        "    elif i<len(speakers_time)-1:\n",
        "        if len(time_processed) and time_processed[-1:][0][1]-time_processed[-1:][0][0]<=MIN_TIME:\n",
        "            time_processed.pop()                    # Si el de la iteración anteior era menor, lo saco\n",
        "        time_processed.append(speakers_time[i])"
      ],
      "metadata": {
        "id": "usNr9cFZDbNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizacion"
      ],
      "metadata": {
        "id": "sEsjABoND92x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Run the interactive demo\n",
        "#interactive_diarization(similarity_dict, wav, wav_splits)"
      ],
      "metadata": {
        "id": "dcefchzsD_-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speech to Text"
      ],
      "metadata": {
        "id": "6R75LbjfDhJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creación de wavs por orador"
      ],
      "metadata": {
        "id": "UYxqBn41H0wS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creacion de los wavs ya separados en los distintos tramos por orador\n",
        "def wavCreation(slices):\n",
        "    if not os.path.exists(\"path/to/demo_folder\"):\n",
        "      os.makedirs(\"/content/temp\")\n",
        "\n",
        "    for slice_index in range(len(slices)):\n",
        "        sliceStart=slices[slice_index][0]\n",
        "        sliceEnd=slices[slice_index][1]\n",
        "        wavfile.write(\"/content/temp/slice\"+str(slice_index)+\".wav\", sampling_rate, wav[sliceStart:sliceEnd].astype(np.float32))\n",
        "\n",
        "wavCreation(time_processed)"
      ],
      "metadata": {
        "id": "aYb5Y7HFDzEQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transcripción"
      ],
      "metadata": {
        "id": "suMBdtOIJAZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def speech2Text(slices):\n",
        "    model = whisper.load_model(\"base\")          #TODO: Revisar tamaño modelo\n",
        "    for slice_index in range(len(slices)):\n",
        "        result = model.transcribe(\"/content/temp/slice\"+str(slice_index)+\".wav\")\n",
        "        os.remove(\"/content/temp/slice\"+str(slice_index)+\".wav\")\n",
        "        slices[slice_index][3]=result['text']\n",
        "\n",
        "speech2Text(time_processed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9XcHn7aI90J",
        "outputId": "2cd7ad36-0f0b-4b29-de85-9c012e69b9c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultado final\n"
      ],
      "metadata": {
        "id": "uxRYV-IeJKWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(time_processed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv4K9Ss1JM9X",
        "outputId": "47192f0f-6a59-453e-c98b-dbcdb4ef515d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 92, 'Kyle Gass', ''], [95, 195, 'Sean Evans', ''], [202, 207, 'Kyle Gass', ''], [213, 535, 'Jack Black', ' you'], [538, 564, 'Kyle Gass', ''], [585, 594, 'Kyle Gass', ''], [595, 628, 'Jack Black', ''], [629, 744, 'Sean Evans', ''], [745, 791, 'Kyle Gass', ''], [792, 825, 'Jack Black', ''], [826, 908, 'Kyle Gass', ''], [928, 933, 'Jack Black', ''], [934, 1184, 'Sean Evans', ' you'], [1185, 1221, 'Jack Black', ''], [1228, 1255, 'Kyle Gass', ''], [1265, 1390, 'Jack Black', ''], [1391, 1408, 'Kyle Gass', ''], [1467, 1764, 'Jack Black', ' you'], [1765, 1790, 'Kyle Gass', ''], [1791, 1847, 'Jack Black', ''], [1848, 1892, 'Kyle Gass', ''], [1893, 1997, 'Jack Black', ''], [2004, 2028, 'Kyle Gass', ''], [2029, 2051, 'Jack Black', '']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO\n",
        "* Agregar opcion debugger\n",
        "* Integrar UI"
      ],
      "metadata": {
        "id": "LfUpe4LXT2n7"
      }
    }
  ]
}